{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import os\n",
    "import csv\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import subprocess\n",
    "import re\n",
    "import operator\n",
    "\n",
    "# basedir = os.path.abspath(os.path.dirname(__file__))\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "annotators = 'tokenize,pos,lemma,ner,parse,natlog'\n",
    "input_file = \"training_sentences.csv\"\n",
    "\n",
    "###################################\n",
    "# Start CoreNLP server\n",
    "################################### \n",
    "# cd /users/hundman/src/stanford-corenlp-full-2015-12-09\n",
    "# java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer 9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "incorrect_parse_trees = [14,15,16,17,18,19,20,43,50,51,60,61,62,63,64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NOTES\n",
    "##############################################################\n",
    "# INCORRECT parse trees (CoreNLP): (14,15,16,17)(18,19)(20,21,22,23)(27)\n",
    "# 14-17 no dependency tree built (just big circle)\n",
    "# 18-19 - no dependency tree built (just big circle)\n",
    "# 20 - incorrect parse (HyMap sentence)  (20-23 are same sentence)\n",
    "# 27,67,68,69 - image(27)/channels(67-69) is technically correct parse, but we really want to identify resolution\n",
    "# 43 - blooming onion (brackets)\n",
    "# 50,51 - blooming onion (brackets)\n",
    "# 60-64 - blooming onion - unit is connected to another word with \"/\" -> (PRISM: 2.5 m/AVNIR: 10 m)\n",
    "\n",
    "# FIXABLE\n",
    "# 28 - just wrong, need to fix\n",
    "# 21-22 - compound where unit isn't connected directly (10, 20 & 60 m)\n",
    "# 31 - gotta find number\n",
    "# 52 - parses fine, just need to handle (1km-resolution)\n",
    "# 57 - parses fine, just need to handle (1-km-resolution)\n",
    "# 58 - this one is hard (not explicity stated, but inferred from prior mention in parenthesis \n",
    "#      -> ETM+pan-chromatic channel (15 m resolution) and ALOS PRISM data (2.5 m))\n",
    "# 72 - need to handle 10 to 90m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Annotations:\n",
    "    def __init__(self, tokens, dependencies):\n",
    "        self.tokens = tokens\n",
    "        self.deps = dependencies\n",
    "        self.pos_lookup = {}\n",
    "    \n",
    "    def build_pos_lookup(self):\n",
    "        \"\"\"dict of part of speech tags for each token. Used to look up POS when iterating through dependencies\n",
    "        { <index> : {\n",
    "                \"word\" : \"\",\n",
    "                \"pos\" : \"\"\n",
    "            }\n",
    "        }\n",
    "        \"\"\"\n",
    "        self.pos_lookup[0] = {\"pos\" : \"\", \"word\": \"\"} #0 not included in tokens, but included in dependencies\n",
    "        for f in self.tokens:\n",
    "            self.pos_lookup[f[\"index\"]] = {}\n",
    "            self.pos_lookup[f[\"index\"]][\"word\"] = f[\"word\"]\n",
    "            self.pos_lookup[f[\"index\"]][\"pos\"] = f[\"pos\"]\n",
    "            \n",
    "            \n",
    "    def find_unit_and_format(self, G, sentence):\n",
    "        for node in G.nodes(data=True):\n",
    "            node = Node(node[0], node[1][\"word\"], node[1][\"pos\"])\n",
    "\n",
    "            # 20 m -> unit matches word and word index is in list of tokens that constitute measurement\n",
    "            if node.word == sentence.unit and node.idx in str(sentence.measure_tokens):\n",
    "                return (\"space_between\", node.idx)\n",
    "\n",
    "            # 10-m -> number and unit are attached\n",
    "            if node.word == sentence.num + \"-\" + sentence.unit and node.word in str(sentence.measure_tokens):\n",
    "                return (\"hyphenated\", node.idx)\n",
    "\n",
    "            # 90m -> if there is a number in the token, replace number with nothing, leaving the unit\n",
    "            if re.search(\"\\d+(.\\d+)*\", node.word) != None:\n",
    "                if sentence.unit == re.sub(\"\\d+(.\\d+)*\", \"\", node.word):\n",
    "                    return (\"attached\", node.idx)\n",
    "\n",
    "        return (None,None)\n",
    "    \n",
    "    def check_output(self, sentence, stats):\n",
    "#         for dep in self.deps:\n",
    "#             print dep\n",
    "        for dep in self.deps:\n",
    "            if not \"dependentGloss\" in dep or not \"governorGloss\" in dep:\n",
    "                stats.parse_error(sentence)\n",
    "                return False\n",
    "        return True\n",
    "                \n",
    "      \n",
    "    \n",
    "class Token:\n",
    "    def __init__(self, index, word, pos, start, end):\n",
    "        self.idx = index\n",
    "        self.word = word\n",
    "        self.pos = pos\n",
    "        self.start = start\n",
    "        self.end = end    \n",
    "        \n",
    "        \n",
    "class Dependency:\n",
    "    def __init__(self, governor, governorGloss, dependent, dependentGloss, dep_type):\n",
    "        self.gov = governorGloss\n",
    "        self.gov_idx = governor\n",
    "        self.dep = dependentGloss\n",
    "        self.dep_idx = dependent\n",
    "        self.dep_type = dep_type\n",
    "        \n",
    "        \n",
    "class Sentence:\n",
    "    def __init__(self, text, measurement_and_type, measurement, entity, unit, number, measurement_type, line_num):\n",
    "        self.text = text\n",
    "        self.extraction_goal = measurement_and_type\n",
    "        self.measurement = measurement\n",
    "        self.entity = entity\n",
    "        self.unit = unit\n",
    "        self.num = number\n",
    "        self.measure_type = measurement_type\n",
    "        self.line_num = line_num\n",
    "        self.measure_tokens = []\n",
    "           \n",
    "    def check_for_measurement(self, token):\n",
    "        \"\"\"Identify the token index numbers for the measurement phrase to \n",
    "        ensure correct tokens are being considered later\"\"\"\n",
    "        measure_start = self.text.index(self.measurement)\n",
    "        if token.start >= measure_start and token.end - 1 <= measure_start + len(self.measurement): #-1 for ending period\n",
    "            self.measure_tokens.append(token.idx)\n",
    "    \n",
    "#     def cleanup(self):\n",
    "        \n",
    "\n",
    "class Node:\n",
    "    def __init__(self, idx, word, pos):\n",
    "        self.idx = idx\n",
    "        self.word = word\n",
    "        self.pos = pos\n",
    "        \n",
    "class Stats:\n",
    "    def __init__(self):\n",
    "        self.pattern_cnts = {}\n",
    "        self.pattern_cnts[\"type\"] = {}\n",
    "        self.pattern_cnts[\"number\"] = {}\n",
    "       \n",
    "        self.errors = {}\n",
    "        self.errors[\"parse\"] = []\n",
    "        self.errors[\"type\"] = {}\n",
    "        self.errors[\"number\"] = {}\n",
    "        \n",
    "        self.errors_cnts = {}\n",
    "        self.errors_cnts[\"parse\"] = 0\n",
    "        self.errors_cnts[\"type\"] = {}\n",
    "        self.errors_cnts[\"number\"] = {}\n",
    "        \n",
    "        self.total_sentences = 0\n",
    "        self.correct_type_cnt = 0\n",
    "        self.correct_num_cnt = 0\n",
    "        self.types_found = []\n",
    "    \n",
    "    def parse_error(self, sentence):\n",
    "#         print \"Parse error: (\" + str(sentence.line_num) + \") \" + sentence.text\n",
    "        self.errors[\"parse\"].append(sentence.line_num)\n",
    "        self.errors_cnts[\"parse\"] += 1\n",
    "        \n",
    "    def evaluate(self, sentence, pattern=\"Unknown\", prediction=\"None\", prediction_type=None):\n",
    "        \n",
    "        print str(prediction_type) + \" pattern: \" + pattern\n",
    "       \n",
    "        if pattern in self.pattern_cnts[prediction_type]:\n",
    "            self.pattern_cnts[prediction_type][pattern] += 1\n",
    "        else:\n",
    "            self.pattern_cnts[prediction_type][pattern] = 1\n",
    "           \n",
    "        matching = sentence.measure_type if prediction_type == \"type\" else sentence.num\n",
    "        if prediction == matching:\n",
    "            pass\n",
    "        else:\n",
    "            if pattern in self.errors[prediction_type] and pattern in self.errors_cnts[prediction_type]:\n",
    "                self.errors[prediction_type][pattern].append(sentence.line_num)\n",
    "                self.errors_cnts[prediction_type][pattern] += 1\n",
    "            else:\n",
    "                self.errors[prediction_type][pattern] = [sentence.line_num]\n",
    "                self.errors_cnts[prediction_type][pattern] = 1\n",
    "    \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_period(dep, last_token_idx):\n",
    "    if dep.gov_idx == last_token_idx:\n",
    "        dep.gov = dep.gov.replace(\".\",\"\")\n",
    "    if dep.dep_idx == last_token_idx:\n",
    "        dep.dep = dep.dep.replace(\".\",\"\")\n",
    "    return dep\n",
    "\n",
    "\n",
    "def get_connected_word(edge, unit_idx, annotated, sentence):\n",
    "    if edge[0] == unit_idx and annotated.pos_lookup[int(edge[1])][\"word\"] != sentence.num:\n",
    "        return edge[1] \n",
    "    elif edge[1] == unit_idx and annotated.pos_lookup[int(edge[0])][\"word\"] != sentence.num:\n",
    "        return edge[0]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_connected_num(edge, unit_idx, annotated, sentence):\n",
    "    if edge[0] == unit_idx and annotated.pos_lookup[int(edge[1])][\"word\"] == sentence.num:\n",
    "        return edge[1] \n",
    "    elif edge[1] == unit_idx and annotated.pos_lookup[int(edge[0])][\"word\"] == sentence.num:\n",
    "        return edge[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "        \n",
    "def get_number(G, sentence, annotated):\n",
    "    # look for first degree connections\n",
    "    for edge in G.edges(data=True):\n",
    "        connected_idx = get_connected_num(edge, unit_idx, annotated, sentence)\n",
    "        if edge[2]['dep'] == \"nummod\" and connected_idx != None:\n",
    "            p_number = G.node[connected_idx]['word']\n",
    "            stats.evaluate(sentence, \"1.1\", p_number, \"number\")\n",
    "            return p_number\n",
    "    \n",
    "    # look for number (CD) in second degree connections\n",
    "    for edge in G.edges(data=True):\n",
    "        connected_idx = get_connected_num(edge, unit_idx, annotated, sentence)\n",
    "        if connected_idx:\n",
    "            second_degree = G.edges([connected_idx])\n",
    "            for edge in second_degree:\n",
    "                for node in edge:\n",
    "                    if annotated.pos_lookup[int(node)]['pos'] == \"CD\":\n",
    "                        p_number = G.node[node]['word']\n",
    "                        stats.evaluate(sentence, \"1.2\", p_number, \"number\")\n",
    "                        return p_number\n",
    "        \n",
    "        \n",
    "        \n",
    "def build_graph(annotated, show=False):\n",
    "    G = nx.Graph()\n",
    "    node_labels, edge_labels = {}, {}\n",
    "    for idx, dep in enumerate(annotated.deps):\n",
    "        dep = Dependency(dep[\"governor\"], dep[\"governorGloss\"], dep[\"dependent\"], dep[\"dependentGloss\"], dep[\"dep\"])\n",
    "        dep = remove_period(dep, len(annotated.tokens))\n",
    "        \n",
    "        # nodes, edges\n",
    "        G.add_node(str(dep.gov_idx), word=dep.gov, pos=annotated.pos_lookup[dep.gov_idx][\"pos\"])\n",
    "        G.add_node(str(dep.dep_idx), word=dep.dep, pos=annotated.pos_lookup[dep.dep_idx][\"pos\"])\n",
    "        G.add_edge(str(dep.dep_idx), str(dep.gov_idx), dep=dep.dep_type)\n",
    "\n",
    "        #labels\n",
    "        node_labels[dep.gov_idx] = dep.gov + \" : \" + annotated.pos_lookup[dep.gov_idx][\"pos\"]\n",
    "        node_labels[dep.dep_idx] = dep.dep + \" : \" + annotated.pos_lookup[dep.dep_idx][\"pos\"]\n",
    "        edge_labels[(str(dep.dep_idx), str(dep.gov_idx))] = dep.dep_type\n",
    "        \n",
    "    pos=nx.spring_layout(G)\n",
    "    \n",
    "#     nx.draw_networkx(G, pos, labels=node_labels)\n",
    "#     nx.draw_networkx_edge_labels(G,pos,edge_labels=edge_labels)\n",
    "#     pylab.show()\n",
    "    \n",
    "    return G\n",
    "    \n",
    "    \n",
    "\n",
    "def space_between_patterns(G, sentence, annotated):\n",
    "    \"\"\" Typical patterns when unit and number are separated by a single space (10 m)\"\"\"\n",
    "    for edge in G.edges(data=True):\n",
    "        connected_idx = get_connected_word(edge, unit_idx, annotated, sentence)\n",
    "        \n",
    "        if connected_idx:\n",
    "            # sentence 79\n",
    "            if edge[2]['dep'] == \"nsubj\":\n",
    "                p_type = G.node[connected_idx]['word']\n",
    "                stats.evaluate(sentence, \"1.1\", p_type, \"type\")\n",
    "                return p_type\n",
    "\n",
    "            #if p_number is present, then measurement type is connected via \"appos\", \"nmod:of\", \"nmod:with\", \"nmod:npmod\"\n",
    "            elif edge[2]['dep'] == \"appos\" or edge[2]['dep'] == \"nmod:of\" or edge[2]['dep'] == \"nmod:with\": #Might need to check for noun NN, or NNS\n",
    "                print edge[2]['dep']\n",
    "                p_type = G.node[connected_idx]['word']\n",
    "                stats.evaluate(sentence, \"1.2\", p_type, \"type\")\n",
    "                return p_type\n",
    "\n",
    "            # eventually will be an indication of inexact value (about)\n",
    "            elif edge[2]['dep'] == \"nmod:about\": \n",
    "                p_type = G.node[connected_idx]['word']\n",
    "                stats.evaluate(sentence, \"1.3\", p_type, \"type\")\n",
    "                return p_type\n",
    "\n",
    "            # inspired by sentence on line 9\n",
    "            elif edge[2]['dep'] == \"compound\" and \"NN\" in G.node[connected_idx][\"pos\"]:\n",
    "                p_type = G.node[connected_idx]['word']\n",
    "                stats.evaluate(sentence, \"1.4\", p_type, \"type\")\n",
    "                return p_type\n",
    "            \n",
    "            # inspired by sentence on line 26\n",
    "            elif edge[2]['dep'] == \"nmod:npmod\":\n",
    "                p_type = evaluate_target_dep(connected_idx, G.edges(data=True), annotated)\n",
    "                stats.evaluate(sentence, \"1.6\", p_type, \"type\")\n",
    "                return p_type\n",
    "\n",
    "                    \n",
    "            # inspired by sentence on line 31\n",
    "            elif edge[2]['dep'] == \"nmod:as\":\n",
    "                p_type = G.node[connected_idx]['word']\n",
    "                stats.evaluate(sentence, \"1.7\", p_type, \"type\")\n",
    "                return p_type\n",
    "\n",
    "\n",
    "    return None\n",
    "        \n",
    "    \n",
    "    \n",
    "def get_dep_nodes(edges, annotations, connected_idx):\n",
    "    dep_nodes = []\n",
    "    for edge in edges:\n",
    "        if edge[2][\"dep\"] == \"dep\" and connected_idx == edge[0]: \n",
    "            dep_nodes.append(edge[1])\n",
    "        if edge[2][\"dep\"] == \"dep\" and connected_idx == edge[1]: \n",
    "            dep_nodes.append(edge[0])\n",
    "    return dep_nodes\n",
    "            \n",
    "    \n",
    "    \n",
    "def evaluate_target_dep(dep_idx, edges, annotations):\n",
    "    # NOT HANDLING MORE THAN ONE 'NN' COMING FROM 'JJ' RIGHT NOW\n",
    "    if \"NN\" in annotations.pos_lookup[int(dep_idx)][\"pos\"]:\n",
    "        return annotations.pos_lookup[int(dep_idx)][\"word\"]\n",
    "    if \"JJ\" in annotations.pos_lookup[int(dep_idx)][\"pos\"]:\n",
    "        for edge in edges:\n",
    "            if \"mod\" in edge[2]['dep'] and dep_idx == edge[0]:\n",
    "                if \"NN\" in annotations.pos_lookup[int(edge[1])][\"pos\"]:\n",
    "                    return annotations.pos_lookup[int(edge[1])][\"word\"]\n",
    "            elif \"mod\" in edge[2]['dep'] and dep_idx == edge[1]:\n",
    "                if \"NN\" in annotations.pos_lookup[int(edge[0])][\"pos\"]:\n",
    "                    return annotations.pos_lookup[int(edge[0])][\"word\"]\n",
    "            else:\n",
    "                print \"UNSEEN 'DEP' COMBO\"\n",
    "              \n",
    "            \n",
    "            \n",
    "def determine_target_dep(dep_indices, stats, annotations, edges):\n",
    "    # check and see if any of dep node words have been found already in patterns with more certainty\n",
    "    # if not, choose the one with fewer edges coming from it\n",
    "    counts = {}\n",
    "    for dep_idx in dep_indices:\n",
    "        if annotations.pos_lookup[int(dep_idx)][\"word\"] in stats.types_found:\n",
    "            return dep_idx\n",
    "        else:\n",
    "            for edge in edges:\n",
    "                if dep_idx in edge[0] or dep_idx in edge[1]:\n",
    "                    if dep_idx in counts:\n",
    "                        counts[dep_idx] += 1\n",
    "                    else:\n",
    "                        counts[dep_idx] = 1\n",
    "            return min(counts.iteritems(), key=operator.itemgetter(1))[0]\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "def uncertain_parse_patterns(G, sentence, annotations, stats):\n",
    "    \"\"\" \n",
    "    If none of typical patterns exist for measurements with space between (10 m), \n",
    "    the dependency type coming from the unit will be \"dep\", and a different set of patterns\n",
    "    will be evaluated here.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        for edge in G.edges(data=True):\n",
    "            connected_idx = get_connected_word(edge, unit_idx, annotations, sentence)\n",
    "\n",
    "            if connected_idx:\n",
    "                p_type = None\n",
    "                dep_indices = get_dep_nodes(G.edges(data=True), annotations, connected_idx)\n",
    "                if len(dep_indices) == 1:\n",
    "                    p_type = evaluate_target_dep(dep_indices[0], G.edges(data=True), annotations)\n",
    "                    stats.evaluate(sentence, \"1.5.1\", p_type, \"type\")\n",
    "                    return p_type\n",
    "                else:\n",
    "                    dep_idx = determine_target_dep(dep_indices, stats, annotations, G.edges(data=True))\n",
    "                    p_type = evaluate_target_dep(dep_idx, G.edges(data=True), annotations)\n",
    "                    stats.evaluate(sentence, \"1.5.2\", p_type, \"type\")\n",
    "                    return p_type\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "        \n",
    "def hyphenated_patterns(g, sentence, annotated):\n",
    "    \"\"\" Typical patterns when unit and number are attached with a hyphen (10-m)\"\"\"\n",
    "    for edge in G.edges(data=True):\n",
    "        connected_idx = get_connected_word(edge, unit_idx, annotated, sentence)\n",
    "        \n",
    "        if edge[2]['dep'] == \"amod\":\n",
    "            p_type = G.node[connected_idx]['word']\n",
    "            stats.evaluate(sentence, \"2.1\", p_type, \"type\")\n",
    "            return True\n",
    "        \n",
    "#     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type pattern: 1.4\n",
      "To measure surface displacements between pairs of Landsat 8 OLI panchromatic images (band 8, 15 m pixel resolution) resulting from ice flow, we find peaks in normalized cross-correlation surfaces calculated at integer pixel offsets between image chips.\n",
      "2\n",
      "\n",
      "Actual Number: 15\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: resolution\n",
      "\n",
      "type: True\n",
      "number: False\n",
      "========================\n",
      "\n",
      "number pattern: 1.1\n",
      "appos\n",
      "type pattern: 1.2\n",
      "The spatial resolution of Landsat 8 (30 m) does not support distinction between single trees and tree clusters nor their defoliation state.\n",
      "3\n",
      "\n",
      "Actual Number: 30\n",
      "Predicted Number: 30\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: resolution\n",
      "\n",
      "type: True\n",
      "number: True\n",
      "========================\n",
      "\n",
      "type pattern: 1.4\n",
      "Landsat 7 spatial resolution is similar to Landsat 8, with 15 m ground-equivalent pixels for the panchromatic band, and 30 m pixels for the visible, near infrared, and short-wave infrared bands.\n",
      "4\n",
      "\n",
      "Actual Number: 15\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: pixels\n",
      "Predicted Type: pixels\n",
      "\n",
      "type: True\n",
      "number: False\n",
      "========================\n",
      "\n",
      "type pattern: 1.4\n",
      "Landsat 7 spatial resolution is similar to Landsat 8, with 15 m ground-equivalent pixels for the panchromatic band, and 30 m pixels for the visible, near infrared, and short-wave infrared bands.\n",
      "5\n",
      "\n",
      "Actual Number: 30\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: pixels\n",
      "Predicted Type: pixels\n",
      "\n",
      "type: True\n",
      "number: False\n",
      "========================\n",
      "\n",
      "type pattern: Unknown\n",
      "Landsat 8 has maintained a high acquisition rate, currently capturing ~725 images per day over the 16-day orbit repeat cycle, leading to excellent image coverage (Fig. 1). \n",
      "6\n",
      "\n",
      "Actual Number: 16\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: cycle\n",
      "Predicted Type: None\n",
      "\n",
      "type: False\n",
      "number: False\n",
      "========================\n",
      "\n",
      "type pattern: 1.4\n",
      "For cloud detection, we use MOD35_L2, the MODIS cloud mask product, gridded to 1 km resolution (Ackerman et al., 2010).\n",
      "7\n",
      "\n",
      "Actual Number: 1\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: resolution\n",
      "\n",
      "type: True\n",
      "number: False\n",
      "========================\n",
      "\n",
      "number pattern: 1.1\n",
      "appos\n",
      "type pattern: 1.2\n",
      "The relatively coarse resolution (1 km) of the MODIS cloud detection methodology as compared to the surface area of each 10 km river segment (between 5 and 40 km2 ) means changing the algorithm's percent cloud tolerance has little impact on the number of segments classified as cloudy.\n",
      "8\n",
      "\n",
      "Actual Number: 1\n",
      "Predicted Number: 1\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: resolution\n",
      "\n",
      "type: True\n",
      "number: True\n",
      "========================\n",
      "\n",
      "number pattern: 1.1\n",
      "type pattern: 1.4\n",
      "The Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER), which was developed by the Ministry of International Trade and Industry (METI), Japan and was launched onboard NASA's Terra satellite in 1999, is intended to obtain global surface spectral emissivity by a five-band TIR radiometer at a spatial resolution 90 m.\n",
      "9\n",
      "\n",
      "Actual Number: 90\n",
      "Predicted Number: 90\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: resolution\n",
      "\n",
      "type: True\n",
      "number: True\n",
      "========================\n",
      "\n",
      "number pattern: 1.1\n",
      "nmod:of\n",
      "type pattern: 1.2\n",
      "ASTER is also equipped with three bands in the visible and near-infrared (NIR) regions and six bands in the shortwave infrared (SWIR) region at spatial resolutions of 15 m and 30 m, respectively.\n",
      "10\n",
      "\n",
      "Actual Number: 15\n",
      "Predicted Number: 15\n",
      "\n",
      "\n",
      "Actual Type: resolutions\n",
      "Predicted Type: resolutions\n",
      "\n",
      "type: True\n",
      "number: True\n",
      "========================\n",
      "\n",
      "number pattern: 1.1\n",
      "nmod:of\n",
      "type pattern: 1.2\n",
      "ASTER is also equipped with three bands in the visible and near-infrared (NIR) regions and six bands in the shortwave infrared (SWIR) region at spatial resolutions of 15 m and 30 m, respectively.\n",
      "11\n",
      "\n",
      "Actual Number: 30\n",
      "Predicted Number: 30\n",
      "\n",
      "\n",
      "Actual Type: resolutions\n",
      "Predicted Type: resolutions\n",
      "\n",
      "type: True\n",
      "number: True\n",
      "========================\n",
      "\n",
      "type pattern: 1.4\n",
      "Sentinel-2 offers a multispectral sensor with 13 bands from 443 to 2190 nm, and a 10 day repeat cycle.\n",
      "12\n",
      "\n",
      "Actual Number: 10\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: cycle\n",
      "Predicted Type: cycle\n",
      "\n",
      "type: True\n",
      "number: False\n",
      "========================\n",
      "\n",
      "appos\n",
      "type pattern: 1.2\n",
      "Sentinel-2 is ESA's medium spatial resolution (10-60 m) super-spectral instrument aimed at ensuring data continuity for global land surface monitoring of Landsat and SPOT.\n",
      "13\n",
      "\n",
      "Actual Number: Oct-60\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: resolution\n",
      "\n",
      "type: True\n",
      "number: False\n",
      "========================\n",
      "\n",
      "number pattern: 1.1\n",
      "nmod:with\n",
      "type pattern: 1.2\n",
      "The Sentinel-2 mission is a medium spatial resolution, super-spectral instrument with a large field of view (290 km), a high revisit capability (5 days with two satellites), a high resolution (10 m, 20 m and 60 m) and a moderately large band set (13 spectral bands).\n",
      "14\n",
      "\n",
      "Actual Number: 5\n",
      "Predicted Number: 5\n",
      "\n",
      "\n",
      "Actual Type: capability\n",
      "Predicted Type: satellites\n",
      "\n",
      "type: False\n",
      "number: True\n",
      "========================\n",
      "\n",
      "number pattern: 1.1\n",
      "type pattern: 1.5.1\n",
      "The Sentinel-2 mission is a medium spatial resolution, super-spectral instrument with a large field of view (290 km), a high revisit capability (5 days with two satellites), a high resolution (10 m, 20 m and 60 m) and a moderately large band set (13 spectral bands).\n",
      "15\n",
      "\n",
      "Actual Number: 10\n",
      "Predicted Number: 10\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: resolution\n",
      "\n",
      "type: True\n",
      "number: True\n",
      "========================\n",
      "\n",
      "number pattern: 1.1\n",
      "type pattern: 1.5.2\n",
      "The Sentinel-2 mission is a medium spatial resolution, super-spectral instrument with a large field of view (290 km), a high revisit capability (5 days with two satellites), a high resolution (10 m, 20 m and 60 m) and a moderately large band set (13 spectral bands).\n",
      "16\n",
      "\n",
      "Actual Number: 20\n",
      "Predicted Number: 20\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: m\n",
      "\n",
      "type: False\n",
      "number: True\n",
      "========================\n",
      "\n",
      "type pattern: 1.4\n",
      "After spectral resampling, the data were spatially resampled from the 4 m HyMAP pixel resolution to the 10, 20 & 60 m resolutions of Sentinel-2 bands and 15 & 30 m ASTER bands using pixel aggregation (neighbourhood averaging).\n",
      "20\n",
      "\n",
      "Actual Number: 4\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: pixel\n",
      "\n",
      "type: False\n",
      "number: False\n",
      "========================\n",
      "\n",
      "type pattern: Unknown\n",
      "After spectral resampling, the data were spatially resampled from the 4 m HyMAP pixel resolution to the 10, 20 & 60 m resolutions of Sentinel-2 bands and 15 & 30 m ASTER bands using pixel aggregation (neighbourhood averaging).\n",
      "21\n",
      "\n",
      "Actual Number: 10\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolutions\n",
      "Predicted Type: None\n",
      "\n",
      "type: False\n",
      "number: False\n",
      "========================\n",
      "\n",
      "type pattern: Unknown\n",
      "After spectral resampling, the data were spatially resampled from the 4 m HyMAP pixel resolution to the 10, 20 & 60 m resolutions of Sentinel-2 bands and 15 & 30 m ASTER bands using pixel aggregation (neighbourhood averaging).\n",
      "22\n",
      "\n",
      "Actual Number: 20\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolutions\n",
      "Predicted Type: None\n",
      "\n",
      "type: False\n",
      "number: False\n",
      "========================\n",
      "\n",
      "type pattern: 1.4\n",
      "After spectral resampling, the data were spatially resampled from the 4 m HyMAP pixel resolution to the 10, 20 & 60 m resolutions of Sentinel-2 bands and 15 & 30 m ASTER bands using pixel aggregation (neighbourhood averaging).\n",
      "23\n",
      "\n",
      "Actual Number: 60\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolutions\n",
      "Predicted Type: resolutions\n",
      "\n",
      "type: True\n",
      "number: False\n",
      "========================\n",
      "\n",
      "type pattern: 1.4\n",
      "True (R: band 4, G: band 3, B: band 2) and false (R: band 8, G: band 4, B: band 3) colour composites of the simulated Sentinel-2 image with 10 m resolution.\n",
      "24\n",
      "\n",
      "Actual Number: 10\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: resolution\n",
      "\n",
      "type: True\n",
      "number: False\n",
      "========================\n",
      "\n",
      "type pattern: 1.4\n",
      "The 10 m resolution of four of the Sentinel-2 bands was appropriate for deriving objects using multi-resolution segmentation.\n",
      "25\n",
      "\n",
      "Actual Number: 10\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: resolution\n",
      "\n",
      "type: True\n",
      "number: False\n",
      "========================\n",
      "\n",
      "type pattern: 1.4\n",
      "This may be related to the 10 m pixel size of the simulated Sentinel-2 data, which is too small for SLC to model forest environments: there are not enough trees in a pixel for the spatial distribution of crowns and empty spaces to be homogenous.\n",
      "26\n",
      "\n",
      "Actual Number: 10\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: size\n",
      "Predicted Type: size\n",
      "\n",
      "type: True\n",
      "number: False\n",
      "========================\n",
      "\n",
      "number pattern: 1.1\n",
      "UNSEEN 'DEP' COMBO\n",
      "UNSEEN 'DEP' COMBO\n",
      "UNSEEN 'DEP' COMBO\n",
      "UNSEEN 'DEP' COMBO\n",
      "UNSEEN 'DEP' COMBO\n",
      "UNSEEN 'DEP' COMBO\n",
      "UNSEEN 'DEP' COMBO\n",
      "UNSEEN 'DEP' COMBO\n",
      "UNSEEN 'DEP' COMBO\n",
      "UNSEEN 'DEP' COMBO\n",
      "UNSEEN 'DEP' COMBO\n",
      "UNSEEN 'DEP' COMBO\n",
      "UNSEEN 'DEP' COMBO\n",
      "UNSEEN 'DEP' COMBO\n",
      "UNSEEN 'DEP' COMBO\n",
      "UNSEEN 'DEP' COMBO\n",
      "UNSEEN 'DEP' COMBO\n",
      "type pattern: 1.6\n",
      "A 1 m spatial resolution 17-band CASI (Compact Airborne Spectrographic Imager) image of Heron Reef, Australia, was used to generate corresponding simulated SPOT-4, ETM+ and Sentinel 2 imagery.\n",
      "27\n",
      "\n",
      "Actual Number: 1\n",
      "Predicted Number: 1\n",
      "\n",
      "\n",
      "Actual Type: image\n",
      "Predicted Type: m\n",
      "\n",
      "type: False\n",
      "number: True\n",
      "========================\n",
      "\n",
      "type pattern: 1.4\n",
      "Sentinel 2's 10 m pixel resolution is lower than the 4 m to sub-2 m multispectral resolutions of the commercial offerings, but Sentinel 2's bands are in general narrower, and this has been demonstrated here as an important factor.\n",
      "28\n",
      "\n",
      "Actual Number: 10\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: pixel\n",
      "\n",
      "type: False\n",
      "number: False\n",
      "========================\n",
      "\n",
      "number pattern: 1.1\n",
      "UNSEEN 'DEP' COMBO\n",
      "type pattern: 1.6\n",
      "Carreiras, Vasconcelos, and Lucas (2012) mapped AGB in heterogeneous vegetation areas of Guinea-Bissau with 2008 ALOS PALSAR mosaic at 50 m spatial resolution.\n",
      "29\n",
      "\n",
      "Actual Number: 50\n",
      "Predicted Number: 50\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: m\n",
      "\n",
      "type: False\n",
      "number: True\n",
      "========================\n",
      "\n",
      "number pattern: 1.1\n",
      "With the launch of the Advanced Land Observing Satellite (ALOS) in 2006, the Japanese Space Agency (JAXA) took the initiative to implement the first global-scale systematic acquisition strategy for satellite sensors at fine and medium (2.5-20 m) spatial resolution.\n",
      "30\n",
      "\n",
      "Actual Number: 2.5-20\n",
      "Predicted Number: 2.5-20\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: None\n",
      "\n",
      "type: False\n",
      "number: True\n",
      "========================\n",
      "\n",
      "type pattern: 1.7\n",
      "The ALOS BOS supported a variety applications from local to global scales, ranging from structural deformation, monitoring of wetlands regional inundation patterns and mapping of forest extent and changes over nations and continents at spatial resolutions as fine as 10 m.\n",
      "31\n",
      "\n",
      "Actual Number: 10\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolutions\n",
      "Predicted Type: resolutions\n",
      "\n",
      "type: True\n",
      "number: False\n",
      "========================\n",
      "\n",
      "type pattern: 1.4\n",
      "Four global mosaics of Advanced Land Observing Satellite (ALOS) Phased Arrayed L-band Synthetic Aperture Radar (SAR) HH and HV polarization data were generated at 25 m spatial resolution using data acquired annually from 2007 to 2010.\n",
      "32\n",
      "\n",
      "Actual Number: 25\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: resolution\n",
      "\n",
      "type: True\n",
      "number: False\n",
      "========================\n",
      "\n",
      "number pattern: 1.1\n",
      "The spatial resolution of the FNF maps generated using the ALOS PALSAR data was also much finer (25 m spatial resolution) allowing greater detail to be resolved.\n",
      "33\n",
      "\n",
      "Actual Number: 25\n",
      "Predicted Number: 25\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: None\n",
      "\n",
      "type: False\n",
      "number: True\n",
      "========================\n",
      "\n",
      "number pattern: 1.1\n",
      "type pattern: 1.6\n",
      "At a global level, mosaics of ALOS PALSAR data were generated for 2007, 2008, 2009 and 2010 at 25 m spatial resolution.\n",
      "34\n",
      "\n",
      "Actual Number: 25\n",
      "Predicted Number: 25\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: resolution\n",
      "\n",
      "type: True\n",
      "number: True\n",
      "========================\n",
      "\n",
      "type pattern: Unknown\n",
      "However, current methodologies of interpreting the PALSAR data are specific to each study site. The objective of this paper is to develop method for savanna biomass mapping at 25 m resolution that can be adapted to large regions using ALOS PALSAR mosaic data.\n",
      "35\n",
      "\n",
      "Actual Number: 25\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: None\n",
      "\n",
      "type: False\n",
      "number: False\n",
      "========================\n",
      "\n",
      "type pattern: Unknown\n",
      "Sixty-two ALOS PALSAR mosaics with 25-m resolution over all of Cameroon from dates 2007, 2008, 2009 and 2010 were supplied by JAXA.\n",
      "36\n",
      "\n",
      "Actual Number: 25\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: None\n",
      "\n",
      "type: False\n",
      "number: False\n",
      "========================\n",
      "\n",
      "type pattern: Unknown\n",
      "The Landsat data, which have 30-m resolution, yielded unclear glacier boundaries, whereas ALOS data, which have 10-m resolution, provided better-defined glacier boundaries.\n",
      "37\n",
      "\n",
      "Actual Number: 10\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: None\n",
      "\n",
      "type: False\n",
      "number: False\n",
      "========================\n",
      "\n",
      "type pattern: Unknown\n",
      "The Landsat data, which have 30-m resolution, yielded unclear glacier boundaries, whereas ALOS data, which have 10-m resolution, provided better-defined glacier boundaries.\n",
      "38\n",
      "\n",
      "Actual Number: 30\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: None\n",
      "\n",
      "type: False\n",
      "number: False\n",
      "========================\n",
      "\n",
      "number pattern: 1.1\n",
      "type pattern: Unknown\n",
      "The optical sensor ASTER is a Japanese sensor on the Terra satellite and offers high-resolution (15-90 m2 per pixel) images of Earth with 14 electromagnetic spectral bands ranging from visible to thermal infrared light (Jet Propulsion Laboratory at California the Institute of Technology, 2004).\n",
      "39\n",
      "\n",
      "Actual Number: 15-90\n",
      "Predicted Number: 15-90\n",
      "\n",
      "\n",
      "Actual Type: high-resolution\n",
      "Predicted Type: None\n",
      "\n",
      "type: False\n",
      "number: True\n",
      "========================\n",
      "\n",
      "type pattern: 1.4\n",
      "The results showed that the synthesized point cloud data from ALOS/PRISM triplets produce vertical distributions similar to LiDAR data and detected the vertical structure of sparse and non-closed forests at 30 m resolution. \n",
      "40\n",
      "\n",
      "Actual Number: 30\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: resolution\n",
      "\n",
      "type: True\n",
      "number: False\n",
      "========================\n",
      "\n",
      "number pattern: 1.1\n",
      "nmod:of\n",
      "type pattern: 1.2\n",
      "ZY03 is specifically designed for the collection of stereo imagery with a resolution of 3.6 m for forward and backward views and 2.1 m for the nadir view similar to ALOS/PRISM.\n",
      "41\n",
      "\n",
      "Actual Number: 3.6\n",
      "Predicted Number: 3.6\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: resolution\n",
      "\n",
      "type: True\n",
      "number: True\n",
      "========================\n",
      "\n",
      "type pattern: Unknown\n",
      "Currently, Landsat-8 and Landast-7 will assure an eight-day repeat coverage for monitoring the entire Earth, especially for mapping crop growth and forest disturbances.\n",
      "44\n",
      "\n",
      "Actual Number: eight\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: coverage\n",
      "Predicted Type: None\n",
      "\n",
      "type: False\n",
      "number: False\n",
      "========================\n",
      "\n",
      "number pattern: 1.1\n",
      "UNSEEN 'DEP' COMBO\n",
      "UNSEEN 'DEP' COMBO\n",
      "UNSEEN 'DEP' COMBO\n",
      "UNSEEN 'DEP' COMBO\n",
      "UNSEEN 'DEP' COMBO\n",
      "UNSEEN 'DEP' COMBO\n",
      "UNSEEN 'DEP' COMBO\n",
      "UNSEEN 'DEP' COMBO\n",
      "UNSEEN 'DEP' COMBO\n",
      "UNSEEN 'DEP' COMBO\n",
      "type pattern: 1.6\n",
      "They have 100 m spatial resolution and image coincidently with the Operational Land Imager (OLI), also on-board Landsat-8.\n",
      "45\n",
      "\n",
      "Actual Number: 100\n",
      "Predicted Number: 100\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: m\n",
      "\n",
      "type: False\n",
      "number: True\n",
      "========================\n",
      "\n",
      "type pattern: Unknown\n",
      "This ETM_ crown cover map is then averaged to a 500-m resolution to validate the MODIS map.\n",
      "46\n",
      "\n",
      "Actual Number: 500\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: None\n",
      "\n",
      "type: False\n",
      "number: False\n",
      "========================\n",
      "\n",
      "type pattern: Unknown\n",
      "The greater scatter at 500-m spatial resolution is probably an artifact of resampling in the MODIS data.\n",
      "47\n",
      "\n",
      "Actual Number: 500\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: None\n",
      "\n",
      "type: False\n",
      "number: False\n",
      "========================\n",
      "\n",
      "type pattern: Unknown\n",
      "MODIS-estimated percent tree crown cover at 500-m resolution.\n",
      "48\n",
      "\n",
      "Actual Number: 500\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: None\n",
      "\n",
      "type: False\n",
      "number: False\n",
      "========================\n",
      "\n",
      "type pattern: Unknown\n",
      "MODIS information is used to estimateglobal terrestrial primary production weekly and annually in near-real time at a 1-km resolution.\n",
      "49\n",
      "\n",
      "Actual Number: 1\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: None\n",
      "\n",
      "type: False\n",
      "number: False\n",
      "========================\n",
      "\n",
      "type pattern: Unknown\n",
      "The mean vector in the spectral and spatial domain within a class is used for class identification, and a final 1km-resolution classification mask is generated for such a field of view in a MODIS granule.\n",
      "52\n",
      "\n",
      "Actual Number: 1\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: None\n",
      "\n",
      "type: False\n",
      "number: False\n",
      "========================\n",
      "\n",
      "type pattern: Unknown\n",
      "MODIS measures radiances in bands 1 and 2 at 0.25-km spatial resolution, in bands 3-7 at 0.5-km resolution, and the remaining 29 bands at 1-km resolution (see Table 1 for the MODIS spectral band specification; the numbers in this table are available online at http://modis.gsfc.nasa.gov/about/specs.html).\n",
      "53\n",
      "\n",
      "Actual Number: 0.25\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: None\n",
      "\n",
      "type: False\n",
      "number: False\n",
      "========================\n",
      "\n",
      "type pattern: Unknown\n",
      "MODIS measures radiances in bands 1 and 2 at 0.25-km spatial resolution, in bands 3-7 at 0.5-km resolution, and the remaining 29 bands at 1-km resolution (see Table 1 for the MODIS spectral band specification; the numbers in this table are available online at http://modis.gsfc.nasa.gov/about/specs.html).\n",
      "54\n",
      "\n",
      "Actual Number: 1\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: None\n",
      "\n",
      "type: False\n",
      "number: False\n",
      "========================\n",
      "\n",
      "type pattern: Unknown\n",
      "MODIS measures radiances in bands 1 and 2 at 0.25-km spatial resolution, in bands 3-7 at 0.5-km resolution, and the remaining 29 bands at 1-km resolution (see Table 1 for the MODIS spectral band specification; the numbers in this table are available online at http://modis.gsfc.nasa.gov/about/specs.html).\n",
      "55\n",
      "\n",
      "Actual Number: 0.5\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: None\n",
      "\n",
      "type: False\n",
      "number: False\n",
      "========================\n",
      "\n",
      "type pattern: Unknown\n",
      "The 1-km-resolution ML classification mask improves the 1-km-resolution MODIS cloud mask in some situations.\n",
      "56\n",
      "\n",
      "Actual Number: 1\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: None\n",
      "\n",
      "type: False\n",
      "number: False\n",
      "========================\n",
      "\n",
      "type pattern: Unknown\n",
      "The 1-km-resolution ML classification mask improves the 1-km-resolution MODIS cloud mask in some situations.\n",
      "57\n",
      "\n",
      "Actual Number: 1\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: None\n",
      "\n",
      "type: False\n",
      "number: False\n",
      "========================\n",
      "\n",
      "number pattern: 1.1\n",
      "appos\n",
      "type pattern: 1.2\n",
      "Pan-sharpening of the applied multispectral satellite data using the Landsat 7 ETM+pan-chromatic channel (15 m resolution) and ALOS PRISM data (2.5 m) was used to support manual mapping of such glacier boundaries (see Methods).\n",
      "58\n",
      "\n",
      "Actual Number: 2.5\n",
      "Predicted Number: 2.5\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: data\n",
      "\n",
      "type: False\n",
      "number: True\n",
      "========================\n",
      "\n",
      "type pattern: 1.4\n",
      "Pan-sharpening of the applied multispectral satellite data using the Landsat 7 ETM+pan-chromatic channel (15 m resolution) and ALOS PRISM data (2.5 m) was used to support manual mapping of such glacier boundaries (see Methods).\n",
      "59\n",
      "\n",
      "Actual Number: 15\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: resolution\n",
      "\n",
      "type: True\n",
      "number: False\n",
      "========================\n",
      "\n",
      "number pattern: 1.1\n",
      "nmod:of\n",
      "type pattern: 1.2\n",
      "The ALOS/PRISM sensor includes a nadir, forward, and backward sensor, generating a stereoscopic image data set of 35_35 km (triplet mode) and 70_35 km (nadir only) with a spatial resolution of 2.5 m.\n",
      "65\n",
      "\n",
      "Actual Number: 2.5\n",
      "Predicted Number: 2.5\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: resolution\n",
      "\n",
      "type: True\n",
      "number: True\n",
      "========================\n",
      "\n",
      "ALOS/AVNIR (70_70 km) provides four bands from a visible to near-infrared radiometer with a spatial resolution of 10 m (JAXA, 2009).\n",
      "66\n",
      "\n",
      "Actual Number: 10\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: None\n",
      "\n",
      "type: False\n",
      "number: False\n",
      "========================\n",
      "\n",
      "type pattern: 1.4\n",
      "The ASTER sensor offers data from three 15 meter pixel resolution visible-NIR channels, six 30 meter pixel resolution SWIR channels and five 90 meter pixel resolution TIR channels [3].\n",
      "67\n",
      "\n",
      "Actual Number: 15\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: channels\n",
      "Predicted Type: channels\n",
      "\n",
      "type: True\n",
      "number: False\n",
      "========================\n",
      "\n",
      "type pattern: 1.4\n",
      "The ASTER sensor offers data from three 15 meter pixel resolution visible-NIR channels, six 30 meter pixel resolution SWIR channels and five 90 meter pixel resolution TIR channels [3].\n",
      "68\n",
      "\n",
      "Actual Number: 30\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: channels\n",
      "Predicted Type: channels\n",
      "\n",
      "type: True\n",
      "number: False\n",
      "========================\n",
      "\n",
      "type pattern: 1.4\n",
      "The ASTER sensor offers data from three 15 meter pixel resolution visible-NIR channels, six 30 meter pixel resolution SWIR channels and five 90 meter pixel resolution TIR channels [3].\n",
      "69\n",
      "\n",
      "Actual Number: 90\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: channels\n",
      "Predicted Type: channels\n",
      "\n",
      "type: True\n",
      "number: False\n",
      "========================\n",
      "\n",
      "nmod:of\n",
      "type pattern: 1.2\n",
      "Visible-shortwave hyperspectral AMS (HyMap) and multispectral TIMS data sets were used to produce simulated ASTER data The AMS data, acquired in 1998 with an instantaneous field of view (IFOV) of 5 m, consisted of 96 bands in the 0.53-2.41 mm region and FWHM spectral resolutions of 12-18 nm. \n",
      "70\n",
      "\n",
      "Actual Number: 18-Dec\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolutions\n",
      "Predicted Type: resolutions\n",
      "\n",
      "type: True\n",
      "number: False\n",
      "========================\n",
      "\n",
      "type pattern: Unknown\n",
      "The Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER) is a high spatial resolution multi-spectral imaging radiometer, and spectrally covers the visible and near-infrared, short-wave-infrared, and thermal infrared regions with 14 spectral bands, 15 to 90m spatial resolution, and 60 km imaging swath. \n",
      "71\n",
      "\n",
      "Actual Number: 15 to 90\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: None\n",
      "\n",
      "type: False\n",
      "number: False\n",
      "========================\n",
      "\n",
      "type pattern: 1.4\n",
      "The Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER) is a high spatial resolution multi-spectral imaging radiometer, and spectrally covers the visible and near-infrared, short-wave-infrared, and thermal infrared regions with 14 spectral bands, 15 to 90m spatial resolution, and 60 km imaging swath. \n",
      "72\n",
      "\n",
      "Actual Number: 60\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: swatch\n",
      "Predicted Type: imaging\n",
      "\n",
      "type: False\n",
      "number: False\n",
      "========================\n",
      "\n",
      "appos\n",
      "type pattern: 1.2\n",
      "The pair of Sentinel-2 satellites will routinely provide high resolution (10-20 m) optical images globally with frequent revisits tailored to the needs of GMES land and emergency services. \n",
      "73\n",
      "\n",
      "Actual Number: 20-Oct\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: resolution\n",
      "\n",
      "type: True\n",
      "number: False\n",
      "========================\n",
      "\n",
      "number pattern: 1.1\n",
      "nmod:of\n",
      "type pattern: 1.2\n",
      "Results confirm the importance of the red-edge bands on particularly Sentinel-2 for agricultural applications, because of the combination with its high spatial resolution of 20 m.\n",
      "74\n",
      "\n",
      "Actual Number: 20\n",
      "Predicted Number: 20\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: resolution\n",
      "\n",
      "type: True\n",
      "number: True\n",
      "========================\n",
      "\n",
      "number pattern: 1.1\n",
      "appos\n",
      "type pattern: 1.2\n",
      "However, both MERIS and OLCI combine a worse spatial resolution (300 m) with a better spectral resolution (about 10 nm), making it applicable at other spatial scales than Sentinel-2 data.\n",
      "75\n",
      "\n",
      "Actual Number: 300\n",
      "Predicted Number: 300\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: resolution\n",
      "\n",
      "type: True\n",
      "number: True\n",
      "========================\n",
      "\n",
      "number pattern: 1.1\n",
      "type pattern: 1.3\n",
      "However, both MERIS and OLCI combine a worse spatial resolution (300 m) with a better spectral resolution (about 10 nm), making it applicable at other spatial scales than Sentinel-2 data.\n",
      "76\n",
      "\n",
      "Actual Number: 10\n",
      "Predicted Number: 10\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: resolution\n",
      "\n",
      "type: True\n",
      "number: True\n",
      "========================\n",
      "\n",
      "nmod:of\n",
      "type pattern: 1.2\n",
      "With a spatial resolution of 10-60 m, Sentinel-2 is designed to address medium-resolution applications.\n",
      "77\n",
      "\n",
      "Actual Number: Oct-60\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: resolution\n",
      "\n",
      "type: True\n",
      "number: False\n",
      "========================\n",
      "\n",
      "number pattern: 1.1\n",
      "nmod:of\n",
      "type pattern: 1.2\n",
      "The Sentinel-2 mission will include twin satellites 180 degrees apart from one another providing a global revisit time of five days (two days in extended mode).\n",
      "78\n",
      "\n",
      "Actual Number: five\n",
      "Predicted Number: five\n",
      "\n",
      "\n",
      "Actual Type: time\n",
      "Predicted Type: time\n",
      "\n",
      "type: True\n",
      "number: True\n",
      "========================\n",
      "\n",
      "number pattern: 1.1\n",
      "type pattern: 1.1\n",
      "Since the spatial resolution of VENuS is 10 m and Sentinel-2 is 10-20 m, in the relevant bands, both sensors are in the range of the optimal LAI accuracy for NDVI.\n",
      "79\n",
      "\n",
      "Actual Number: 10\n",
      "Predicted Number: 10\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: resolution\n",
      "\n",
      "type: True\n",
      "number: True\n",
      "========================\n",
      "\n",
      "type pattern: 1.1\n",
      "Since the spatial resolution of VENuS is 10 m and Sentinel-2 is 10-20 m, in the relevant bands, both sensors are in the range of the optimal LAI accuracy for NDVI.\n",
      "80\n",
      "\n",
      "Actual Number: 20-Oct\n",
      "Predicted Number: None\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: Sentinel-2\n",
      "\n",
      "type: False\n",
      "number: False\n",
      "========================\n",
      "\n",
      "number pattern: 1.1\n",
      "nmod:of\n",
      "type pattern: 1.2\n",
      "Each S2 satellite carries a Multi-Spectral Imager (MSI) with a swath of 290 km.\n",
      "81\n",
      "\n",
      "Actual Number: 290\n",
      "Predicted Number: 290\n",
      "\n",
      "\n",
      "Actual Type: swath\n",
      "Predicted Type: swath\n",
      "\n",
      "type: True\n",
      "number: True\n",
      "========================\n",
      "\n",
      "number pattern: 1.1\n",
      "Compared to the 4 IKO PS bands, WV2-4Trad increased spatial resolution (1 m to 0.5 m), and WV2-4Add included 4 additional bands (wavelengths).\n",
      "82\n",
      "\n",
      "Actual Number: 1\n",
      "Predicted Number: 1\n",
      "\n",
      "\n",
      "Actual Type: resolution\n",
      "Predicted Type: None\n",
      "\n",
      "type: False\n",
      "number: True\n",
      "========================\n",
      "\n",
      "Total Sentences: 81\n",
      "\n",
      "Number of parse errors: [17L, 18L, 19L, 42L, 43L, 50L, 51L, 60L, 61L, 62L, 63L, 64L]\n",
      "Parse errors: 12\n",
      "\n",
      "Correct numbers: 25\n",
      "Incorrect numbers: \n",
      "\n",
      "Correct types: 35\n",
      "Incorrect types: \n",
      "   1.4: [20L, 28L, 72L]\n",
      "   1.6: [27L, 29L, 45L]\n",
      "   1.1: [80L]\n",
      "   1.2: [14L, 58L]\n",
      "   Unknown: [6L, 21L, 22L, 35L, 36L, 37L, 38L, 39L, 44L, 46L, 47L, 48L, 49L, 52L, 53L, 54L, 55L, 56L, 57L, 71L]\n",
      "   1.5.2: [16L]\n"
     ]
    }
   ],
   "source": [
    "stats = Stats()\n",
    "\n",
    "with open(input_file, \"rU\") as f:\n",
    "    sentences = csv.reader(f)\n",
    "    for row in sentences:\n",
    "#         if sentences.line_num == 15:\n",
    "        if sentences.line_num > 1: #skip header\n",
    "            stats.total_sentences += 1\n",
    "            \n",
    "            # load sentence data into class object and clean sentence \n",
    "            sentence = Sentence(row[1], row[4] + row[13], row[4], row[3],row[14],row[13],row[15], sentences.line_num)\n",
    "#             sentence.cleanup()\n",
    "            \n",
    "            # Parse sentence, load annotations into class object\n",
    "            output = nlp.annotate(sentence.text, properties={'annotators': annotators, 'outputFormat':'json'})\n",
    "            annotations = Annotations(output[\"sentences\"][0][\"tokens\"], output[\"sentences\"][0][\"collapsed-ccprocessed-dependencies\"])\n",
    "            \n",
    "            # Check for legitimate output from coreNLP\n",
    "            if annotations.check_output(sentence, stats) == True:\n",
    "            \n",
    "                # Build part of speech lookup for a given token index\n",
    "                annotations.build_pos_lookup()\n",
    "\n",
    "                # Load parse tree into graph\n",
    "                G = build_graph(annotations, show=True)\n",
    "\n",
    "                # find measurement tokens (used to find exact unit index later)\n",
    "                for x in annotations.tokens:\n",
    "                    token = Token(x[\"index\"], x[\"word\"], x[\"pos\"], x[\"characterOffsetBegin\"], x[\"characterOffsetEnd\"])\n",
    "                    sentence.check_for_measurement(token)\n",
    "\n",
    "                #\n",
    "                p_number, p_type, p_adjectives, p_type_idx = None, None, None, None\n",
    "\n",
    "                # Find exactly where the unit token is (even if partial match)\n",
    "                unit_idx = annotations.find_unit_and_format(G, sentence)[1]\n",
    "\n",
    "                # Determine the format the measurement (space, hyphen, no space, range)\n",
    "                measurement_format = annotations.find_unit_and_format(G, sentence)[0]\n",
    "\n",
    "                p_number = get_number(G, sentence, annotations)\n",
    "\n",
    "                if measurement_format == \"space_between\":\n",
    "                    p_type = space_between_patterns(G, sentence, annotations)\n",
    "                    if p_type == None:\n",
    "                        p_type = uncertain_parse_patterns(G, sentence, annotations, stats)\n",
    "                elif measurement_format == \"hyphenated\":\n",
    "                    p_type = hyphenated_patterns(G, sentence, annotations)\n",
    "                else:\n",
    "                    stats.evaluate(sentence, \"Unknown\", \"None\", \"type\")\n",
    "\n",
    "\n",
    "                # Sentence results (make function)\n",
    "                print sentence.text\n",
    "                print sentence.line_num\n",
    "                print \"\"\n",
    "                print \"Actual Number: \" + sentence.num\n",
    "                print \"Predicted Number: \" + str(p_number)\n",
    "                print \"\"\n",
    "                \n",
    "                print \"\"\n",
    "                print \"Actual Type: \" + sentence.measure_type\n",
    "                print \"Predicted Type: \" + str(p_type)\n",
    "                print \"\"\n",
    "                if p_type == sentence.measure_type:\n",
    "                    stats.correct_type_cnt += 1\n",
    "                    print \"type: True\"\n",
    "                else:\n",
    "                    print \"type: False\"\n",
    "                if p_number == sentence.num:\n",
    "                    stats.correct_num_cnt += 1\n",
    "                    print \"number: True\"\n",
    "                else:\n",
    "                    print \"number: False\"\n",
    "                print \"========================\"\n",
    "                print \"\"\n",
    "   \n",
    "    # All results (make function)\n",
    "    print \"Total Sentences: \" + str(stats.total_sentences)\n",
    "    print \"\"\n",
    "    print \"Number of parse errors: \" + str(stats.errors[\"parse\"])\n",
    "    print \"Parse errors: \" + str(stats.errors_cnts[\"parse\"])\n",
    "    print \"\"\n",
    "    print \"Correct numbers: \" + str(stats.correct_num_cnt)\n",
    "    print \"Incorrect numbers: \"\n",
    "    for key, value in stats.errors[\"number\"].iteritems():\n",
    "        print \"   \" + key + \": \" + str(value)\n",
    "    print \"\"\n",
    "    print \"Correct types: \" + str(stats.correct_type_cnt)\n",
    "    print \"Incorrect types: \"\n",
    "    for key, value in stats.errors[\"type\"].iteritems():\n",
    "        print \"   \" + key + \": \" + str(value)\n",
    "    \n",
    "            \n",
    "# self.pattern_cnts = {}\n",
    "#         self.pattern_cnts[\"type\"] = {}\n",
    "#         self.pattern_cnts[\"number\"] = {}\n",
    "       \n",
    "#         self.errors = {}\n",
    "#         self.errors[\"type\"] = {}\n",
    "#         self.errors[\"number\"] = {}\n",
    "        \n",
    "#         self.errors_cnts = {}\n",
    "#         self.errors_cnts[\"type\"] = {}\n",
    "#         self.errors_cnts[\"number\"] = {}\n",
    "        \n",
    "#         self.total_sentences = 0\n",
    "#         self.correct_type_cnt = 0\n",
    "#         self.correct_num_cnt = 0\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
